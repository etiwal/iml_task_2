{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "# explicitly require this experimental feature\n",
    "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
    "# now you can import normally from sklearn.impute\n",
    "from sklearn.impute import IterativeImputer, SimpleImputer\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.svm import LinearSVR, SVR, SVC,LinearSVC\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.preprocessing import normalize \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier, RidgeClassifierCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils import dataset_imputer, get_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "df_training_features = pd.read_csv('train_features.csv')\n",
    "df_training_labels = pd.read_csv('train_labels.csv')\n",
    "all_pids = [pid for pid in df_training_features['pid'].unique()]\n",
    "\n",
    "pids_train, pids_val = train_test_split(all_pids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPatientData(trainingData, pids, patients=0, mode='pid'):\n",
    "    if mode == 'number':\n",
    "        pids = all_pids[:patients]\n",
    "    if len(pids) == 0:\n",
    "        return trainingData\n",
    "    #pids = np.array(pids).astype(np.float)\n",
    "    patients = [trainingData.iloc[idx] for idx in range(0, len(trainingData)) if trainingData['pid'][idx] in pids]    \n",
    "    #patientTrainingDataIndex = [trainingData.iloc[idx] for idx, col in enumerate(trainingData) if trainingData['pid'][idx] in pids]    \n",
    "    return pd.DataFrame(patients)\n",
    "\n",
    "def partitionData(trainingDataPids, trainingPartition=80):\n",
    "    validationPartition = 100 - trainingPartition\n",
    "    countTraining = int((trainingPartition/100)*len(trainingDataPids))\n",
    "    training = trainingDataPids[:countTraining]\n",
    "    validation = trainingDataPids[countTraining:]\n",
    "    print('')\n",
    "    print('Training size: ' + str(countTraining))\n",
    "    print('Validation size: ' + str(len(validation)))\n",
    "    return training, validation\n",
    "\n",
    "def populateData(X,Y):\n",
    "    Z = pd.merge(X, Y, on='pid')\n",
    "    YData = Z[Y.columns].iloc[:,1:]\n",
    "    XData = Z[X.columns].iloc[:,1:]\n",
    "    return XData, YData\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "TESTS = ['LABEL_BaseExcess', 'LABEL_Fibrinogen', 'LABEL_AST', 'LABEL_Alkalinephos', 'LABEL_Bilirubin_total',\n",
    "         'LABEL_Lactate', 'LABEL_TroponinI', 'LABEL_SaO2',\n",
    "         'LABEL_Bilirubin_direct', 'LABEL_EtCO2']\n",
    "\n",
    "#def get_score(df_true, df_submission):\n",
    "#    df_submission = df_submission.sort_values('pid')\n",
    "#    df_true = df_true.sort_values('pid')\n",
    "#    \n",
    "#    task1 = np.mean([metrics.roc_auc_score(df_true[entry], df_submission[entry]) for entry in TESTS])\n",
    "#    #task2 = metrics.roc_auc_score(df_true['LABEL_Sepsis'], df_submission['LABEL_Sepsis'])\n",
    "#    #task3 = np.mean([0.5 + 0.5 * np.maximum(0, metrics.r2_score(df_true[entry], df_submission[entry])) for entry in VITALS])\n",
    "#    #score = np.mean([task1, task2, task3])\n",
    "#    return task1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\api.py:107: RuntimeWarning: '<' not supported between instances of 'str' and 'int', sort order is undefined for incomparable objects\n",
      "  result = result.union(other)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 %\n"
     ]
    }
   ],
   "source": [
    "X_pid_train = dataset_imputer(df_training_features, method='count', pid_list=pids_train, fillna=True)\n",
    "X_pid_val = dataset_imputer(df_training_features, method='count', pid_list=pids_val, fillna=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0 % - completed\n",
      "\n",
      "100.0 % - completed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_pid_train = dataset_imputer(df_training_labels, method=None, pid_list=pids_train, fillna=True)\n",
    "Y_pid_val = dataset_imputer(df_training_labels, method=None, pid_list=pids_val, fillna=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def impute_count(df)\n",
    "#     X_pid_train = pd.DataFrame(columns=df.columns)\n",
    "#     for pid in all_pids:\n",
    "#         uniqueData = df_training_original[df_training_original['pid']==pid]\n",
    "#         counts = uniqueData.isna().sum()\n",
    "#         counts = -1*counts + 12\n",
    "#         counts['pid'] = pid\n",
    "#         counts['Age'] = uniqueData['Age'].iloc[0]\n",
    "#         counts = pd.DataFrame(counts).transpose()\n",
    "#         X_pid_train = pd.concat([X_pid_train, counts])\n",
    "#         #counts.drop('Time', inplace=True)\n",
    "    \n",
    "    \n",
    "# print(X_pid_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You are trying to merge on object and int64 columns. If you wish to proceed you should use pd.concat",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-8f90fffacb0e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgg3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_pid_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_training_label\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mgg3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgg3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgg3\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mgg3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m38\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgg3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m     59\u001b[0m                          \u001b[0mright_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mright_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msuffixes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msuffixes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m                          \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindicator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindicator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                          validate=validate)\n\u001b[0m\u001b[0;32m     62\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    553\u001b[0m         \u001b[1;31m# validate the merge keys dtypes. We may need to coerce\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[1;31m# to avoid incompat dtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_coerce_merge_keys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    556\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m         \u001b[1;31m# If argument passed to validate,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m_maybe_coerce_merge_keys\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    984\u001b[0m             elif (not is_numeric_dtype(lk)\n\u001b[0;32m    985\u001b[0m                     and (is_numeric_dtype(rk) and not is_bool_dtype(rk))):\n\u001b[1;32m--> 986\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mis_datetimelike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlk\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_datetimelike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: You are trying to merge on object and int64 columns. If you wish to proceed you should use pd.concat"
     ]
    }
   ],
   "source": [
    "gg3 = pd.merge(X_pid_train, df_training_label )\n",
    "gg3 = gg3.astype(float)\n",
    "print(gg3[gg3.columns[:38]].head())\n",
    "print(len(gg3.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gg3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-e40314fce142>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgg3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m38\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mcorr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgg3\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mgg3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m45\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m35\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m ax = sns.heatmap(\n",
      "\u001b[1;31mNameError\u001b[0m: name 'gg3' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,8))\n",
    "print(gg3.columns[10:38])\n",
    "corr = gg3[gg3.columns[1:-5]].corr()\n",
    "f = plt.figure(figsize=(45, 35))\n",
    "ax = sns.heatmap(\n",
    "    corr, \n",
    "    vmin=-1, vmax=1, center=0,\n",
    "    cmap=sns.diverging_palette(20, 220, n=200),\n",
    "    square=True, annot=True\n",
    ")\n",
    "ax.set_xticklabels(\n",
    "    ax.get_xticklabels(),\n",
    "    rotation=45,\n",
    "    horizontalalignment='right'\n",
    ");\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_pid_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-0f91e2e69656>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#x_train = X_pid_train[['pid', 'PTT', 'HCO3', 'BaseExcess', 'PaCO2', 'FiO2', 'SaO2','Chloride', 'Hct', 'pH']]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_pid_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_pid_val\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY_pid_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_pid_val\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m feature_columns = ['pid', 'Time', 'Age', 'EtCO2', 'PTT', 'BUN', 'Lactate', 'Temp', 'Hgb',\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_pid_train' is not defined"
     ]
    }
   ],
   "source": [
    "#x_train = X_pid_train[['pid', 'PTT', 'HCO3', 'BaseExcess', 'PaCO2', 'FiO2', 'SaO2','Chloride', 'Hct', 'pH']]\n",
    "x_train, x_val = X_pid_train.copy(), X_pid_val.copy()\n",
    "y_train, y_val = Y_pid_train.copy(), Y_pid_val.copy()\n",
    "\n",
    "feature_columns = ['pid', 'Time', 'Age', 'EtCO2', 'PTT', 'BUN', 'Lactate', 'Temp', 'Hgb',\n",
    "                 'HCO3', 'BaseExcess', 'RRate', 'Fibrinogen', 'Phosphate', 'WBC',\n",
    "                 'Creatinine', 'PaCO2', 'AST', 'FiO2', 'Platelets', 'SaO2', 'Glucose',\n",
    "                 'ABPm', 'Magnesium', 'Potassium', 'ABPd', 'Calcium', 'Alkalinephos',\n",
    "                 'SpO2', 'Bilirubin_direct', 'Chloride', 'Hct', 'Heartrate',\n",
    "                 'Bilirubin_total', 'TroponinI', 'ABPs', 'pH']\n",
    "\n",
    "x_train, x_val = x_train[feature_columns], x_val[feature_columns]\n",
    "\n",
    "label_columns = ['pid', 'LABEL_BaseExcess', 'LABEL_Fibrinogen', 'LABEL_AST',\n",
    "                 'LABEL_Alkalinephos', 'LABEL_Bilirubin_total', 'LABEL_Lactate',\n",
    "                 'LABEL_TroponinI', 'LABEL_SaO2', 'LABEL_Bilirubin_direct',\n",
    "                 'LABEL_EtCO2']\n",
    "\n",
    "y_train, y_val = y_train[label_columns], y_val[label_columns]\n",
    "\n",
    "print(x_train.head())\n",
    "print('*'*100)\n",
    "print(y_train.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       pid  LABEL_BaseExcess  LABEL_Fibrinogen  LABEL_AST  LABEL_Alkalinephos  \\\n",
      "0        1               1.0               0.0        0.0                 0.0   \n",
      "6622     2               0.0               0.0        0.0                 0.0   \n",
      "15008    4               0.0               0.0        0.0                 0.0   \n",
      "16335    6               1.0               0.0        0.0                 0.0   \n",
      "17676    8               0.0               0.0        0.0                 0.0   \n",
      "\n",
      "       LABEL_Bilirubin_total  LABEL_Lactate  LABEL_TroponinI  LABEL_SaO2  \\\n",
      "0                        0.0            1.0              0.0         0.0   \n",
      "6622                     0.0            0.0              1.0         0.0   \n",
      "15008                    0.0            0.0              0.0         1.0   \n",
      "16335                    0.0            0.0              0.0         1.0   \n",
      "17676                    0.0            0.0              0.0         0.0   \n",
      "\n",
      "       LABEL_Bilirubin_direct  LABEL_EtCO2  \n",
      "0                         0.0          0.0  \n",
      "6622                      0.0          0.0  \n",
      "15008                     0.0          0.0  \n",
      "16335                     0.0          0.0  \n",
      "17676                     0.0          0.0  \n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18995, 37)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\etien\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(100, 100), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
       "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "              power_t=0.5, random_state=1, shuffle=True, solver='sgd',\n",
       "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train MLPClassifier\n",
    "#regr =   KNeighborsClassifier(3)\n",
    "regr = MLPClassifier(alpha=1e-5,hidden_layer_sizes=(100,100), random_state=1, solver='sgd', max_iter=200)\n",
    "#regr = RidgeClassifierCV()\n",
    "#regr = RandomForestClassifier()\n",
    "trainNumbers = 16000\n",
    "regr.fit(x_train.iloc[:trainNumbers,2:], df_training_label.iloc[:trainNumbers,1:-5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  pid Time Age EtCO2 PTT BUN Lactate Temp Hgb HCO3 ... Alkalinephos SpO2  \\\n",
      "0   1   12  34     0   0   3       0    8   3    3 ...            0   12   \n",
      "0   2   12  34     0   1   1       0    3   1    0 ...            0   11   \n",
      "0   4   12  34     0   1   2       0    3   2    0 ...            1   11   \n",
      "0   6   12  34     0   1   2       2   12   6    2 ...            0   12   \n",
      "0   8   12  34     0   0   1       0    3   0    0 ...            0   10   \n",
      "\n",
      "  Bilirubin_direct Chloride Hct Heartrate Bilirubin_total TroponinI ABPs pH  \n",
      "0                0        3   6        12               0         0   12  7  \n",
      "0                0        0   1        11               0         1   11  0  \n",
      "0                1        0   2        11               1         1   11  0  \n",
      "0                0        2  10        12               0         0   12  7  \n",
      "0                0        0   0        11               0         1   11  0  \n",
      "\n",
      "[5 rows x 37 columns]\n",
      "       LABEL_BaseExcess  LABEL_Fibrinogen  LABEL_AST  LABEL_Alkalinephos  \\\n",
      "0                   1.0               0.0        0.0                 0.0   \n",
      "6622                0.0               0.0        0.0                 0.0   \n",
      "15008               0.0               0.0        0.0                 0.0   \n",
      "16335               1.0               0.0        0.0                 0.0   \n",
      "17676               0.0               0.0        0.0                 0.0   \n",
      "\n",
      "       LABEL_Bilirubin_total  LABEL_Lactate  LABEL_TroponinI  LABEL_SaO2  \\\n",
      "0                        0.0            1.0              0.0         0.0   \n",
      "6622                     0.0            0.0              1.0         0.0   \n",
      "15008                    0.0            0.0              0.0         1.0   \n",
      "16335                    0.0            0.0              0.0         1.0   \n",
      "17676                    0.0            0.0              0.0         0.0   \n",
      "\n",
      "       LABEL_Bilirubin_direct  LABEL_EtCO2  \n",
      "0                         0.0          0.0  \n",
      "6622                      0.0          0.0  \n",
      "15008                     0.0          0.0  \n",
      "16335                     0.0          0.0  \n",
      "17676                     0.0          0.0  \n"
     ]
    }
   ],
   "source": [
    "print(x_train.head())\n",
    "print(df_training_label.iloc[:5,1:-5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    }
   ],
   "source": [
    "f = regr.predict_proba(x_train.iloc[trainNumbers:,2:])\n",
    "f = pd.DataFrame(f)\n",
    "f.columns = df_training_label.columns[1:-5]\n",
    "#f.columns = ['LABEL_BaseExcess1', 'LABEL_BaseExcess']\n",
    "f['pid'] = x_train.iloc[trainNumbers:,0].reset_index(drop=True)\n",
    "\n",
    "print(get_score(df_training_label.iloc[trainNumbers:,:], f, tasks=['task1'])[1])\n",
    "#print(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do prediction with test data\n",
    "\n",
    "test_df = pd.read_csv('test_features.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
